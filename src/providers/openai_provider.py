"""
OpenAI API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å®Ÿè£…

OpenAI APIã‚’ä½¿ç”¨ã—ãŸç¿»è¨³å‡¦ç†ã‚’æä¾›ã™ã‚‹ã€‚
æ—¢å­˜ã®translator.pyã‹ã‚‰OpenAIå›ºæœ‰ã®æ©Ÿèƒ½ã‚’ç§»è¡Œã—ã€BaseProviderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«é©åˆã•ã›ã‚‹ã€‚
"""

import time
from typing import Dict, Any, Optional
from tqdm.auto import tqdm
import tenacity
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from .base_provider import BaseProvider, APIError, HTTPStatusError, RateLimitError
from src.unicode_handler import normalize_unicode_text, validate_text_for_api


class OpenAIProvider(BaseProvider):
    """
    OpenAI APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’å«ã‚€ã€‚
    """
    
    def __init__(self, api_key: str, model_name: Optional[str] = None, timeout: int = 500):
        """
        OpenAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI API ã‚­ãƒ¼
            model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ï¼‰
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
        """
        super().__init__(api_key, model_name, timeout)
        self._openai_client = None  # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨
        
        # OpenAIå›ºæœ‰ã®è¨­å®š
        self._generation_config = {
            "temperature": 0.0
        }
    
    def get_default_model(self) -> str:
        """
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®OpenAIãƒ¢ãƒ‡ãƒ«åã‚’è¿”ã™
        
        Returns:
            ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«å
        """
        return "gpt-4.1"
    
    def _initialize_client(self):
        """
        OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é…å»¶åˆæœŸåŒ–ã™ã‚‹
        """
        if self._openai_client is None:
            try:
                import openai
                self._openai_client = openai.OpenAI(api_key=self.api_key, timeout=self.timeout)
                tqdm.write("OpenAI APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                    
            except ImportError as e:
                raise APIError(f"OpenAI APIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            except Exception as e:
                raise APIError(f"OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _validate_response(self, response) -> str:
        """
        OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¤œè¨¼ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            response: OpenAI APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            APIError: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼ãŒä¸æ­£ãªå ´åˆ
        """
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®åŸºæœ¬æ¤œè¨¼
        if not response.choices or len(response.choices) == 0:
            raise APIError("OpenAI APIã‹ã‚‰ã®å¿œç­”ã«choicesãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å­˜åœ¨ç¢ºèª
        if not hasattr(response.choices[0], 'message') or not hasattr(response.choices[0].message, 'content'):
            raise APIError("OpenAI APIã‹ã‚‰ã®å¿œç­”ã®å½¢å¼ãŒä¸æ­£ã§ã™")
        
        content = response.choices[0].message.content
        if not content:
            raise APIError("OpenAI APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")
        
        return content
    
    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=3, min=10, max=180),
        retry=retry_if_exception_type((
            ConnectionError, TimeoutError, HTTPStatusError, APIError,
            UnicodeEncodeError, Exception
        )),
        reraise=True
    )
    def translate(self, text: str, prompt: str) -> str:
        """
        OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã™ã‚‹
        
        Args:
            text: ç¿»è¨³å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç¾åœ¨ã¯ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã€promptã«å«ã¾ã‚Œã‚‹ï¼‰
            prompt: ç¿»è¨³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            APIError: APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
            RateLimitError: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ãŸå ´åˆ
        """
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self._initialize_client()
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not self.check_rate_limit():
            remaining_time = self._rate_limit_status["waiting_period"] - (
                time.time() - self._rate_limit_status["last_hit_time"]
            )
            raise RateLimitError(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä¸­: ã‚ã¨{remaining_time:.1f}ç§’å¾…æ©Ÿã—ã¦ãã ã•ã„")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        is_valid, error_msg = validate_text_for_api(prompt)
        if not is_valid:
            tqdm.write(f"  ğŸ”§ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®Unicodeæ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­... ç†ç”±: {error_msg}")
            normalized_prompt, was_modified = normalize_unicode_text(prompt, aggressive=True)
            if was_modified:
                tqdm.write(f"  â†» æ­£è¦åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                prompt = normalized_prompt
            else:
                tqdm.write(f"  â“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ­£è¦åŒ–ã«ã‚ˆã‚‹å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        try:
            # OpenAI APIå‘¼ã³å‡ºã—
            response = self._openai_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=self._generation_config["temperature"]
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼ã¨ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            return self._validate_response(response)
            
        except UnicodeEncodeError as e:
            # UnicodeEncodeErrorå°‚ç”¨ã®å‡¦ç†
            tqdm.write(f"  ! Unicodeå‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†å‡¦ç†ã‚’è©¦è¡Œ
            tqdm.write(f"  ğŸ”§ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®Unicodeæ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­...")
            normalized_prompt, was_modified = normalize_unicode_text(prompt, aggressive=True)
            
            if was_modified:
                tqdm.write(f"  â†» æ­£è¦åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†è©¦è¡Œä¸­...")
                response = self._openai_client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": normalized_prompt}],
                    temperature=self._generation_config["temperature"]
                )
                return self._validate_response(response)
            else:
                tqdm.write(f"  â“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ­£è¦åŒ–ã«ã‚ˆã‚‹å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                raise e
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            error_type = type(e).__name__
            error_msg = str(e)
            
            # HTTPã‚¨ãƒ©ãƒ¼ã®è©³ç´°å‡¦ç†
            if hasattr(e, 'status_code'):
                status_code = e.status_code
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (429) ã®å‡¦ç†
                if status_code == 429:
                    retry_count = getattr(self, '_retry_count', 1)
                    wait_time = 60 + (retry_count * retry_count * 10)
                    self.set_rate_limit_hit(wait_time)
                    tqdm.write(f"  ! ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ: {wait_time}ç§’å¾…æ©Ÿã—ã¾ã™")
                    time.sleep(wait_time)
                    raise RateLimitError(f"OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: {error_msg}")
                
                # ãã®ä»–ã®HTTPã‚¨ãƒ©ãƒ¼
                elif status_code in [503, 504]:
                    tqdm.write(f"  ! ã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ ({status_code}): {error_msg}")
                    raise HTTPStatusError(status_code, f"OpenAI APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {error_msg}")
                else:
                    tqdm.write(f"  ! HTTP ã‚¨ãƒ©ãƒ¼ ({status_code}): {error_msg}")
                    raise HTTPStatusError(status_code, f"OpenAI API HTTPã‚¨ãƒ©ãƒ¼: {error_msg}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ï¼ˆstatus_codeãŒãªã„å ´åˆï¼‰
            elif "rate limit" in error_msg.lower() or "429" in error_msg:
                retry_count = getattr(self, '_retry_count', 1)
                wait_time = 60 + (retry_count * retry_count * 10)
                self.set_rate_limit_hit(wait_time)
                tqdm.write(f"  ! ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ: {wait_time}ç§’å¾…æ©Ÿã—ã¾ã™")
                time.sleep(wait_time)
                raise RateLimitError(f"OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: {error_msg}")
            
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
            else:
                tqdm.write(f"  ! OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ ({error_type}): {error_msg}")
                raise APIError(f"OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {error_msg}")
    
    def validate_api_key(self) -> bool:
        """
        OpenAI APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã™ã‚‹
        
        Returns:
            APIã‚­ãƒ¼ãŒæœ‰åŠ¹ãªå ´åˆã¯True
        """
        try:
            self._initialize_client()
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆå‘¼ã³å‡ºã—ã§ç¢ºèª
            test_response = self._openai_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "Hello"}],
                temperature=0.0,
                max_tokens=10
            )
            return test_response is not None and len(test_response.choices) > 0
        except Exception as e:
            tqdm.write(f"OpenAI APIã‚­ãƒ¼æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def get_rate_limits(self) -> Dict[str, Any]:
        """
        OpenAI APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®šã‚’å–å¾—ã™ã‚‹
        
        Returns:
            ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é–¢ã™ã‚‹è¨­å®šè¾æ›¸
        """
        return {
            "max_requests_per_minute": 500,  # OpenAI APIã®ä¸€èˆ¬çš„ãªåˆ¶é™ï¼ˆãƒ—ãƒ©ãƒ³ã«ã‚ˆã‚‹ï¼‰
            "max_tokens_per_minute": 200000,  # æ¦‚ç®—å€¤
            "max_requests_per_day": 10000,
            "provider": "openai"
        }