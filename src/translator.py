import os
import time
import re
from dotenv import load_dotenv
# é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãŸã‚ã«APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç§»å‹•
import tenacity
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import requests.exceptions
import http.client
import urllib.error
from tqdm.auto import tqdm  # é€²æ—ãƒãƒ¼ã¨è¡çªã—ãªã„å‡ºåŠ›ç”¨ï¼ˆtqdm.writeä½¿ç”¨ï¼‰
from unicode_handler import normalize_unicode_text, validate_text_for_api, detect_surrogate_pairs

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç®¡ç†ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
rate_limit_status = {
    "gemini": {"hit": False, "last_hit_time": 0, "waiting_period": 0},
    "openai": {"hit": False, "last_hit_time": 0, "waiting_period": 0},
    "anthropic": {"hit": False, "last_hit_time": 0, "waiting_period": 0},
    "claude": {"hit": False, "last_hit_time": 0, "waiting_period": 0},
}

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
dotenv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
if not os.path.exists(dotenv_path):
    print(f"\nè­¦å‘Š: .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚{dotenv_path} ã«.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    print("å¿…è¦ãªAPIã‚­ãƒ¼ã®è¨­å®šä¾‹:")
    print("GEMINI_API_KEY=your_gemini_api_key")
    print("OPENAI_API_KEY=your_openai_api_key")
    print("ANTHROPIC_API_KEY=your_anthropic_api_key\n")

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv(dotenv_path)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒªãƒˆãƒ©ã‚¤ã®è¨­å®š
DEFAULT_TIMEOUT = 500  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (ç§’)
MAX_RETRIES = 5        # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆå˜ä¸€ã®ãƒªãƒˆãƒ©ã‚¤ã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆï¼‰

# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨ï¼‰
genai = None
openai_client = None
anthropic_client = None

# ä¾‹å¤–ã‚’ã¾ã¨ã‚ãŸã‚¯ãƒ©ã‚¹å®šç¾©ï¼ˆHTTPã‚¨ãƒ©ãƒ¼ã‚’å«ã‚€ï¼‰
class APIError(Exception):
    """APIã‚¨ãƒ©ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    pass

class HTTPStatusError(APIError):
    """HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼"""
    def __init__(self, status_code, message=None):
        self.status_code = status_code
        self.message = message or f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼: {status_code}"
        super().__init__(self.message)

# ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ã®ã‚¨ãƒ©ãƒ¼ç¨®é¡ã‚’å®šç¾©
RETRY_EXCEPTIONS = (
    ConnectionError,
    TimeoutError,
    requests.exceptions.RequestException,
    requests.exceptions.HTTPError,
    requests.exceptions.ConnectionError,
    requests.exceptions.Timeout,
    http.client.HTTPException,
    urllib.error.HTTPError,
    urllib.error.URLError,
    HTTPStatusError,
    APIError,
    UnicodeEncodeError,  # Unicodeå‡¦ç†ã‚¨ãƒ©ãƒ¼ã‚’è¿½åŠ 
    # Google APIã®ç‰¹å®šã‚¨ãƒ©ãƒ¼ã‚’è¿½åŠ 
    Exception  # DeadlineExceededã‚’å«ã‚€ã™ã¹ã¦ã®ä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒ
)

def extract_gemini_response_text(response) -> str:
    """
    Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        response: Gemini APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        
    Raises:
        APIError: ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        # ğŸ” DEBUG: Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ãƒ­ã‚°
        tqdm.write(f"  ğŸ” DEBUG - Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹èª¿æŸ»:")
        tqdm.write(f"    - response type: {type(response)}")
        tqdm.write(f"    - hasattr candidates: {hasattr(response, 'candidates')}")
        
        if hasattr(response, 'candidates'):
            tqdm.write(f"    - candidates type: {type(response.candidates)}")
            tqdm.write(f"    - candidates length: {len(response.candidates) if response.candidates else 'None'}")
            if response.candidates and len(response.candidates) > 0:
                tqdm.write(f"    - candidate[0] type: {type(response.candidates[0])}")
        
        # 1. candidatesæ§‹é€ ã‚’ã¾ãšç¢ºèªï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
        if hasattr(response, 'candidates') and response.candidates and len(response.candidates) > 0:
            tqdm.write(f"  ğŸ” DEBUG - candidatesé…åˆ—ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­... é•·ã•: {len(response.candidates)}")
            
            try:
                candidate = response.candidates[0]
                tqdm.write(f"  ğŸ” DEBUG - candidate[0]å–å¾—æˆåŠŸ, type: {type(candidate)}")
            except IndexError as idx_err:
                tqdm.write(f"  âŒ DEBUG - candidates[0]ã§IndexError: {str(idx_err)}")
                raise APIError(f"Gemini APIã®candidatesé…åˆ—ãŒç©ºã§ã™ - IndexError: {str(idx_err)}")
            
            if hasattr(candidate, 'content') and candidate.content:
                tqdm.write(f"  ğŸ” DEBUG - contentå­˜åœ¨ç¢ºèª, type: {type(candidate.content)}")
                if hasattr(candidate.content, 'parts') and candidate.content.parts and len(candidate.content.parts) > 0:
                    tqdm.write(f"  ğŸ” DEBUG - partsé…åˆ—ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­... é•·ã•: {len(candidate.content.parts)}")
                    
                    try:
                        part = candidate.content.parts[0]
                        tqdm.write(f"  ğŸ” DEBUG - parts[0]å–å¾—æˆåŠŸ, type: {type(part)}")
                    except IndexError as idx_err:
                        tqdm.write(f"  âŒ DEBUG - parts[0]ã§IndexError: {str(idx_err)}")
                        raise APIError(f"Gemini APIã®partsé…åˆ—ãŒç©ºã§ã™ - IndexError: {str(idx_err)}")
                    
                    if hasattr(part, 'text') and part.text:
                        tqdm.write(f"  âœ… DEBUG - ãƒ†ã‚­ã‚¹ãƒˆå–å¾—æˆåŠŸ, é•·ã•: {len(part.text)}")
                        return part.text
                    else:
                        tqdm.write(f"  âš ï¸ DEBUG - parts[0].textãŒç©ºã¾ãŸã¯ãªã—")
                else:
                    tqdm.write(f"  âš ï¸ DEBUG - partsãŒç©ºã¾ãŸã¯ãªã—")
            else:
                tqdm.write(f"  âš ï¸ DEBUG - contentãŒç©ºã¾ãŸã¯ãªã—")
        else:
            tqdm.write(f"  âš ï¸ DEBUG - candidatesãŒç©ºã¾ãŸã¯ãªã—")
        
        # 2. ç›´æ¥textå±æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if hasattr(response, 'text') and response.text:
            return response.text
        
        # 3. partså±æ€§ã‚’ç›´æ¥ãƒã‚§ãƒƒã‚¯ï¼ˆfallbackï¼‰
        if hasattr(response, 'parts') and response.parts and len(response.parts) > 0:
            if hasattr(response.parts[0], 'text') and response.parts[0].text:
                return response.parts[0].text
        
        # 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚ˆã‚Šè©³ç´°ã«èª¿æŸ»
        tqdm.write("  ! Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ§‹é€ ã‚’è©³ç´°èª¿æŸ»ä¸­...")
        
        # responseã®å±æ€§ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        response_attrs = [attr for attr in dir(response) if not attr.startswith('_')]
        tqdm.write(f"  Debug - åˆ©ç”¨å¯èƒ½ãªå±æ€§: {response_attrs}")
        
        # å„å±æ€§ã®å€¤ã‚’ç¢ºèª
        for attr in ['candidates', 'parts', 'text']:
            if hasattr(response, attr):
                attr_value = getattr(response, attr)
                tqdm.write(f"  Debug - {attr}: {type(attr_value)} - {str(attr_value)[:100]}...")
        
        # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ç©ºã§ãªã„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¢ã™
        if hasattr(response, 'candidates') and response.candidates:
            for i, candidate in enumerate(response.candidates):
                try:
                    if hasattr(candidate, 'content') and candidate.content:
                        if hasattr(candidate.content, 'parts') and candidate.content.parts:
                            for j, part in enumerate(candidate.content.parts):
                                if hasattr(part, 'text') and part.text and part.text.strip():
                                    tqdm.write(f"  âœ“ å€™è£œ{i}ã®ãƒ‘ãƒ¼ãƒˆ{j}ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—")
                                    return part.text
                except (IndexError, AttributeError) as inner_error:
                    tqdm.write(f"  Debug - å€™è£œ{i}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(inner_error)}")
                    continue
        
        # ã¾ã è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä»–ã®å±æ€§ã‚’ç¢ºèª
        for attr_name in ['text', '_result', 'result']:
            if hasattr(response, attr_name):
                attr_value = getattr(response, attr_name)
                if attr_value and str(attr_value).strip():
                    tqdm.write(f"  âœ“ {attr_name}å±æ€§ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—")
                    return str(attr_value)
        
        # ã©ã®æ–¹æ³•ã§ã‚‚å–å¾—ã§ããªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        raise APIError("Gemini APIã‹ã‚‰ã®å¿œç­”ã«æœ‰åŠ¹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
    except IndexError as idx_error:
        # ğŸ” IndexErrorã®è©³ç´°ãªè¨ºæ–­æƒ…å ±ã‚’è¿½åŠ 
        import traceback
        tqdm.write(f"  âŒ CRITICAL - Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã§IndexErrorç™ºç”Ÿ:")
        tqdm.write(f"    - ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(idx_error)}")
        tqdm.write(f"    - ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                tqdm.write(f"      {line}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°æƒ…å ±ã‚’å‡ºåŠ›
        tqdm.write(f"  ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç·Šæ€¥è¨ºæ–­:")
        try:
            tqdm.write(f"    - response.__dict__: {response.__dict__ if hasattr(response, '__dict__') else 'ãªã—'}")
        except:
            tqdm.write(f"    - response.__dict__å–å¾—å¤±æ•—")
        
        raise APIError(f"Gemini APIã‹ã‚‰ã®å¿œç­”ã®å‡¦ç†ä¸­ã«IndexErrorãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(idx_error)}")
    except Exception as other_error:
        tqdm.write(f"  ! ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(other_error)}")
        raise APIError(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(other_error)}")

def extract_headers(text: str) -> list:
    """
    Markdownãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ# ã§å§‹ã¾ã‚‹è¡Œï¼‰ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    
    Args:
        text: ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æŠ½å‡ºã™ã‚‹Markdownãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒªã‚¹ãƒˆ
    """
    headers = []
    for line in text.split('\n'):
        stripped_line = line.strip()
        if stripped_line.startswith('#'):
            headers.append(stripped_line)
    return headers

def clean_markdown_headers(text: str) -> str:
    """
    æ—¢å­˜ã®Markdownãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒ¬ãƒ™ãƒ«ã‚’æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åˆã‚ã›ã¦ä¿®æ­£ã™ã‚‹é–¢æ•°
    æ—¢ã«ãƒ˜ãƒƒãƒ€ãƒ¼è¨˜å·(#)ãŒã¤ã„ã¦ã„ã‚‹è¡Œã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¾ã™
    
    ä¾‹: '# 3.1 æ‰‹æ³•' â†’ '## 3.1 æ‰‹æ³•' (ãƒ‰ãƒƒãƒˆãŒ1ã¤ãªã®ã§##ã«ä¿®æ­£)
    ä¾‹: '### 2 æ–¹æ³•' â†’ '# 2 æ–¹æ³•' (ãƒ‰ãƒƒãƒˆãŒãªã„ã®ã§#ã«ä¿®æ­£)
    
    Args:
        text: æ•´å½¢ã™ã‚‹ç¿»è¨³æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        æ•´å½¢å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    lines = text.split('\n')
    processed_lines = []
    
    # æ•°å­—ã¨ãƒ‰ãƒƒãƒˆã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã™ã‚‹æ­£è¦è¡¨ç¾
    # ä¾‹: "1", "1.2", "1.2.3" ãªã©ã«ãƒãƒƒãƒ
    section_pattern = r'^(\d+(\.\d+)*)\s'
    
    for line in lines:
        trimmed_line = line.lstrip()
        
        # æ—¢å­˜ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ã¿ã‚’å‡¦ç†
        if trimmed_line.startswith('#'):
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¨˜å·ã‚’å‰Šé™¤ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’å–å¾—
            header_text = re.sub(r'^#+\s*', '', trimmed_line)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­ã«æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            match = re.match(section_pattern, header_text)
            
            if match:
                # æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
                section_num = match.group(1)
                # ãƒ‰ãƒƒãƒˆã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ¬ãƒ™ãƒ«ã‚’æ±ºå®š (ãƒ‰ãƒƒãƒˆæ•°+1)
                header_level = section_num.count('.') + 1
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒ¼ã‚«ãƒ¼ã®ä½œæˆï¼ˆä¾‹: ###ï¼‰
                header_marker = '#' * header_level
                # æ–°ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼è¨˜å·ã‚’è¿½åŠ 
                formatted_line = f"{header_marker} {header_text}"
                processed_lines.append(formatted_line)
            else:
                # æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯ãã®ã¾ã¾
                processed_lines.append(line)
        else:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã§ãªã„å ´åˆã¯ãã®ã¾ã¾
            processed_lines.append(line)
    
    return '\n'.join(processed_lines)

@retry(
    stop=stop_after_attempt(MAX_RETRIES),
    wait=wait_exponential(multiplier=3, min=10, max=180),  # ã•ã‚‰ã«é•·ã„ãƒãƒƒã‚¯ã‚ªãƒ•ã‚’è¨­å®š
    retry=retry_if_exception_type(RETRY_EXCEPTIONS),
    reraise=True
)
def call_llm_with_retry(llm_provider, model_name, prompt):
    """
    ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚’æŒã¤LLMå‘¼ã³å‡ºã—é–¢æ•°
    
    Args:
        llm_provider: ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
        model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        prompt: é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
    Returns:
        LLMã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    # ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—
    retry_count = 1
    if hasattr(call_llm_with_retry, 'retry'):
        retry_obj = getattr(call_llm_with_retry, 'retry')
        if hasattr(retry_obj, 'statistics') and retry_obj.statistics.get('attempt_number') is not None:
            retry_count = retry_obj.statistics.get('attempt_number')
    
    try:
        if llm_provider == "gemini":
            # å¿…è¦ãªã¨ãã«ã ã‘Gemini APIã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            global genai
            if genai is None:
                from google import generativeai as genai
                genai.configure(api_key=GEMINI_API_KEY)
                # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
                try:
                    import google.generativeai
                    version_info = getattr(google.generativeai, '__version__', 'unknown')
                    tqdm.write(f"Gemini API ({version_info}) ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                except:
                    tqdm.write("Gemini APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            
            # æ–°ã—ã„GenerativeModelã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½¿ç”¨
            # ğŸ” DEBUG: APIå‘¼ã³å‡ºã—å‰ã®æƒ…å ±
            tqdm.write(f"  ğŸ” DEBUG - Gemini APIå‘¼ã³å‡ºã—:")
            tqdm.write(f"    - model_name: {model_name}")
            tqdm.write(f"    - prompt length: {len(prompt)} æ–‡å­—")
            
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt, generation_config={"temperature": 0.0, "max_output_tokens": 10000})
            
            # ğŸ” DEBUG: APIå¿œç­”å¾Œã®æƒ…å ±
            tqdm.write(f"  ğŸ” DEBUG - Gemini APIå¿œç­”å—ä¿¡:")
            tqdm.write(f"    - response received: {response is not None}")
            
            # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«æŠ½å‡º
            return extract_gemini_response_text(response)
        elif llm_provider == "openai":
            # å¿…è¦ãªã¨ãã«ã ã‘OpenAI APIã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            global openai_client
            if openai_client is None:
                import openai
                openai_client = openai.OpenAI(api_key=OPENAI_API_KEY, timeout=DEFAULT_TIMEOUT)
                tqdm.write("OpenAI APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                
            response = openai_client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼
            if not response.choices or len(response.choices) == 0:
                raise APIError("OpenAI APIã‹ã‚‰ã®å¿œç­”ã«choicesãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            if not hasattr(response.choices[0], 'message') or not hasattr(response.choices[0].message, 'content'):
                raise APIError("OpenAI APIã‹ã‚‰ã®å¿œç­”ã®å½¢å¼ãŒä¸æ­£ã§ã™")
            
            return response.choices[0].message.content
        elif llm_provider in ("claude", "anthropic"):
            # å¿…è¦ãªã¨ãã«ã ã‘Anthropic APIã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            global anthropic_client
            if anthropic_client is None:
                import anthropic
                anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY, timeout=DEFAULT_TIMEOUT)
                tqdm.write("Anthropic APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                
            response = anthropic_client.messages.create(
                model=model_name,
                max_tokens=10000,
                temperature=0.0,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼
            if not hasattr(response, 'content') or not response.content or len(response.content) == 0:
                raise APIError("Anthropic APIã‹ã‚‰ã®å¿œç­”ã«contentãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # content[0]ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not hasattr(response.content[0], 'text'):
                raise APIError("Anthropic APIã‹ã‚‰ã®å¿œç­”ã®å½¢å¼ãŒä¸æ­£ã§ã™")
            
            return response.content[0].text
        else:
            raise ValueError(f"Unknown llm_provider: {llm_provider}")
    except requests.exceptions.HTTPError as e:
        status_code = e.response.status_code if hasattr(e, 'response') and hasattr(e.response, 'status_code') else 0
        
        # 504ã‚¨ãƒ©ãƒ¼ã‚„503ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç‰¹åˆ¥ãªã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å†ç™ºç”Ÿ
        if status_code in [503, 504]:
            error_msg = f"ã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ ({status_code}): {str(e)}"
            # ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆã‚’è¡¨ç¤º
            if retry_count > 1:
                tqdm.write(f"  ! {status_code} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {error_msg}")
            else:
                tqdm.write(f"  ! {status_code} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {error_msg}")
            raise HTTPStatusError(status_code, error_msg)
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (429) ã®å‡¦ç†
        elif status_code == 429:
            error_msg = f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (429): {str(e)}"
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ…‹ã‚’æ›´æ–°
            rate_limit_status[llm_provider]["hit"] = True
            rate_limit_status[llm_provider]["last_hit_time"] = time.time()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰é…å»¶æ™‚é–“æƒ…å ±ã‚’å–å¾—ï¼ˆã‚ã‚Œã°ï¼‰
            retry_delay = None
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                try:
                    error_json = e.response.json()
                    if 'retry_delay' in error_json:
                        retry_seconds = error_json['retry_delay'].get('seconds', 0)
                        if retry_seconds > 0:
                            retry_delay = retry_seconds
                except:
                    pass
            
            # APIãŒæ¨å¥¨ã™ã‚‹å¾…æ©Ÿæ™‚é–“ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ç‹¬è‡ªã®è¨ˆç®—å¼
            if retry_delay:
                wait_time = retry_delay + 10  # APIã®æ¨å¥¨+ä½™è£•
            else:
                # ã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®šï¼ˆãƒªãƒˆãƒ©ã‚¤å›æ•°ã«å¿œã˜ã¦æŒ‡æ•°çš„ã«å¢—åŠ ï¼‰
                wait_time = 60 + (retry_count * retry_count * 10)
            
            # å¾…æ©Ÿæ™‚é–“ã‚’è¨˜éŒ²
            rate_limit_status[llm_provider]["waiting_period"] = wait_time
            
            tqdm.write(f"  ! ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {wait_time}ç§’å¾…æ©Ÿã—ã¾ã™")
            time.sleep(wait_time)  # æ˜ç¤ºçš„ãªå¾…æ©Ÿ
            raise HTTPStatusError(429, error_msg)
        
        # ãã®ä»–ã®HTTPã‚¨ãƒ©ãƒ¼
        error_msg = f"HTTP ã‚¨ãƒ©ãƒ¼ ({status_code}): {str(e)}"
        if retry_count > 1:
            tqdm.write(f"  ! HTTP ã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {error_msg}")
        else:
            tqdm.write(f"  ! HTTP ã‚¨ãƒ©ãƒ¼: {error_msg}")
        raise e
    except UnicodeEncodeError as e:
        # UnicodeEncodeErrorå°‚ç”¨ã®å‡¦ç†
        error_msg = f"UnicodeEncodeError: {str(e)}"
        tqdm.write(f"  ! Unicodeå‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†å‡¦ç†ã‚’è©¦è¡Œ
        try:
            tqdm.write(f"  ğŸ”§ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®Unicodeæ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­...")
            normalized_prompt, was_modified = normalize_unicode_text(prompt, aggressive=True)
            
            if was_modified:
                tqdm.write(f"  â†» æ­£è¦åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†è©¦è¡Œä¸­...")
                # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†åº¦APIå‘¼ã³å‡ºã—
                if llm_provider == "gemini":
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(normalized_prompt, generation_config={"temperature": 0.0, "max_output_tokens": 10000})
                    
                    # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«æŠ½å‡º
                    return extract_gemini_response_text(response)
                elif llm_provider == "openai":
                    response = openai_client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "user", "content": normalized_prompt}],
                        temperature=0.0
                    )
                    return response.choices[0].message.content
                elif llm_provider in ("claude", "anthropic"):
                    response = anthropic_client.messages.create(
                        model=model_name,
                        max_tokens=10000,
                        temperature=0.0,
                        messages=[{"role": "user", "content": normalized_prompt}]
                    )
                    return response.content[0].text
            else:
                tqdm.write(f"  â“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ­£è¦åŒ–ã«ã‚ˆã‚‹å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as retry_error:
            tqdm.write(f"  ! æ­£è¦åŒ–å¾Œã®å†è©¦è¡Œã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {str(retry_error)}")
        
        # æœ€çµ‚çš„ã«UnicodeEncodeErrorã¨ã—ã¦å†ç™ºç”Ÿ
        raise e
    except Exception as e:
        error_type = type(e).__name__
        error_msg = f"{error_type}: {str(e)}"
        
        # IndexErrorã®è©³ç´°ãªæƒ…å ±ã‚’è¿½åŠ 
        if isinstance(e, IndexError):
            import traceback
            tqdm.write(f"  ! IndexErrorè©³ç´°: {traceback.format_exc()}")
        
        # ResourceExhaustedã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰ã®å‡¦ç†
        if "ResourceExhausted" in error_type or "ResourceExhausted" in str(e) or "429" in str(e):
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ…‹ã‚’æ›´æ–°
            rate_limit_status[llm_provider]["hit"] = True
            rate_limit_status[llm_provider]["last_hit_time"] = time.time()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰é…å»¶æ™‚é–“æƒ…å ±ã‚’å–å¾—ï¼ˆã‚ã‚Œã°ï¼‰
            retry_delay = None
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                try:
                    error_json = e.response.json()
                    if 'retry_delay' in error_json:
                        retry_seconds = error_json['retry_delay'].get('seconds', 0)
                        if retry_seconds > 0:
                            retry_delay = retry_seconds
                except:
                    pass
            
            # å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®š
            if retry_delay:
                wait_time = retry_delay + 5  # APIãŒæ¨å¥¨ã™ã‚‹æ™‚é–“+ä½™è£•
            else:
                # ã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®šï¼ˆãƒªãƒˆãƒ©ã‚¤å›æ•°ã«å¿œã˜ã¦å¢—åŠ ï¼‰
                wait_time = 60 + (retry_count * 20)  
            
            # å¾…æ©Ÿæ™‚é–“ã‚’è¨˜éŒ²
            rate_limit_status[llm_provider]["waiting_period"] = wait_time
            
            tqdm.write(f"  ! ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {wait_time}ç§’å¾…æ©Ÿã—ã¾ã™")
            time.sleep(wait_time)  # æ˜ç¤ºçš„ãªå¾…æ©Ÿ
            raise HTTPStatusError(429, f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # DeadlineExceededã‚¨ãƒ©ãƒ¼ã‚’ç‰¹åˆ¥ã«å‡¦ç†
        if "DeadlineExceeded" in error_type or "Deadline Exceeded" in str(e) or "504" in str(e):
            tqdm.write(f"  ! DeadlineExceededã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {error_msg}")
            raise HTTPStatusError(504, f"DeadlineExceeded: {str(e)}")
        
        # ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆã‚’è¡¨ç¤º
        if retry_count > 1:
            tqdm.write(f"  ! APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{MAX_RETRIES}): {error_msg}")
        else:
            tqdm.write(f"  ! APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {error_msg}")
        raise e

@retry(
    stop=stop_after_attempt(MAX_RETRIES),
    wait=wait_exponential(multiplier=4, min=15, max=240),  # ã•ã‚‰ã«é•·ã„ãƒãƒƒã‚¯ã‚ªãƒ•ã‚’è¨­å®š
    retry=retry_if_exception_type(RETRY_EXCEPTIONS),
    reraise=True  # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã¦ãƒ¡ã‚¤ãƒ³å‡¦ç†ã§æ•æ‰ã™ã‚‹
)
def translate_text(text: str, target_lang: str = "ja", page_info=None, llm_provider: str = "gemini", model_name: str = None, previous_headers=None) -> tuple:
    """
    Translate the given text to the target language using the specified LLM provider.
    APIã‚­ãƒ¼ã¯.envã‹ã‚‰èª­ã¿è¾¼ã¿ã€google-generativeaiã€OpenAIã€Anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    
    Args:
        text: ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        target_lang: ç¿»è¨³å…ˆã®è¨€èª
        page_info: {'current': ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ç•ªå·, 'total': åˆè¨ˆãƒšãƒ¼ã‚¸æ•°} ã®å½¢å¼ã®è¾æ›¸
        llm_provider: ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ ("gemini", "openai", "claude", "anthropic")
        model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
        previous_headers: å‰ã®ãƒšãƒ¼ã‚¸ã§ä½¿ç”¨ã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒªã‚¹ãƒˆ
        
    Returns:
        tuple: (ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ, æŠ½å‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒªã‚¹ãƒˆ)
    """
    try:
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ…‹ã‚’ç¢ºèª
        if rate_limit_status[llm_provider]["hit"]:
            current_time = time.time()
            elapsed_since_hit = current_time - rate_limit_status[llm_provider]["last_hit_time"]
            waiting_period = rate_limit_status[llm_provider]["waiting_period"]
            
            # å‰å›ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‹ã‚‰ã®çµŒéæ™‚é–“ãŒå¾…æ©Ÿæ™‚é–“ã‚ˆã‚Šå°‘ãªã‘ã‚Œã°å¾…æ©Ÿ
            if elapsed_since_hit < waiting_period:
                remaining_wait = waiting_period - elapsed_since_hit
                if remaining_wait > 0:
                    tqdm.write(f"  â±ï¸ å‰å›ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‹ã‚‰ {waiting_period}ç§’çµŒéã™ã‚‹ã¾ã§ã‚ã¨{remaining_wait:.1f}ç§’å¾…æ©Ÿã—ã¾ã™")
                    time.sleep(remaining_wait)
            else:
                # å¾…æ©Ÿæ™‚é–“ãŒçµŒéã—ãŸã‚‰ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
                rate_limit_status[llm_provider]["hit"] = False
                tqdm.write(f"  âœ“ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å¾…æ©Ÿæ™‚é–“ãŒçµŒéã—ã¾ã—ãŸã€‚é€šå¸¸å‡¦ç†ã‚’å†é–‹ã—ã¾ã™ã€‚")
        
        # ãƒšãƒ¼ã‚¸æƒ…å ±ãŒã‚ã‚Œã°ã€ãƒ­ã‚°ã«æ®‹ã™
        if page_info:
            page_msg = f"ãƒšãƒ¼ã‚¸ {page_info['current']}/{page_info['total']} ã®ç¿»è¨³ã‚’é–‹å§‹"
            tqdm.write(f"  â€¢ {page_msg}")
        # APIã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
        if llm_provider == "gemini" and not GEMINI_API_KEY:
            return "ç¿»è¨³ã‚¨ãƒ©ãƒ¼: Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚", []
        elif llm_provider == "openai" and not OPENAI_API_KEY:
            return "ç¿»è¨³ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚", []
        elif llm_provider in ("claude", "anthropic") and not ANTHROPIC_API_KEY:
            return "ç¿»è¨³ã‚¨ãƒ©ãƒ¼: Anthropic APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«ANTHROPIC_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚", []
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—æ•°ã‚’å–å¾—
        char_count = len(text)
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®Unicodeå®‰å…¨æ€§ã‚’äº‹å‰ãƒã‚§ãƒƒã‚¯
        is_safe, unicode_error = validate_text_for_api(text)
        if not is_safe:
            tqdm.write(f"  âš ï¸ Unicodeå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {unicode_error}")
            tqdm.write(f"  ğŸ”§ ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­...")
            
            # Unicodeæ­£è¦åŒ–ã‚’é©ç”¨
            normalized_text, was_modified = normalize_unicode_text(text, aggressive=False)
            
            if was_modified:
                tqdm.write(f"  âœ“ Unicodeæ­£è¦åŒ–ãŒé©ç”¨ã•ã‚Œã¾ã—ãŸ")
                text = normalized_text
                char_count = len(text)
                
                # å†åº¦å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                is_safe_after, error_after = validate_text_for_api(text)
                if not is_safe_after:
                    tqdm.write(f"  âš ï¸ ç©æ¥µçš„ãªæ­£è¦åŒ–ã‚’è©¦è¡Œä¸­...")
                    # ã‚ˆã‚Šç©æ¥µçš„ãªæ­£è¦åŒ–ã‚’è©¦è¡Œ
                    aggressive_text, _ = normalize_unicode_text(text, aggressive=True)
                    text = aggressive_text
                    char_count = len(text)
                    tqdm.write(f"  âœ“ ç©æ¥µçš„ãªæ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                tqdm.write(f"  â“ æ­£è¦åŒ–ã«ã‚ˆã‚‹å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæº–å‚™
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«åæ±ºå®š
        if model_name is None:
            if llm_provider == "gemini":
                model_name = "gemini-2.5-flash-preview-04-17"  # åˆ©ç”¨å¯èƒ½ãªæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«
            elif llm_provider == "openai":
                model_name = "gpt-4.1"
            elif llm_provider in ("claude", "anthropic"):
                model_name = "claude-3.7-sonnet"

        # ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        previous_headers_text = ""
        if previous_headers and len(previous_headers) > 0:
            previous_headers_text = "\nä»¥ä¸‹ã¯ã€ã“ã‚Œã¾ã§ã®ãƒšãƒ¼ã‚¸ã§æ¤œå‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼ã®ä¸€è¦§ã§ã™ã€‚ã“ã‚Œã‚‰ã¨ã®ä¸€è²«æ€§ã‚’ä¿ã£ãŸãƒ˜ãƒƒãƒ€ãƒ¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ï¼š\n"
            previous_headers_text += "\n".join(previous_headers)
            previous_headers_text += "\n"
        
        prompt = f"""ã‚ãªãŸã«æ¸¡ã™ã®ã¯è«–æ–‡pdfã®1ãƒšãƒ¼ã‚¸ã‚’æŠ½å‡ºã—ãŸã‚‚ã®ã§ã™ã€‚æ¬¡ã®æ–‡ç« ã‚’{target_lang}èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
ç¿»è¨³ã•ã‚ŒãŸæ–‡ç« ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚åŸæ–‡ã«å¿ å®Ÿã«ç¿»è¨³ã—ã€è‡ªåˆ†ã§æ–‡ç« ã‚’è¶³ã—ãŸã‚Šã‚¹ã‚­ãƒƒãƒ—ã—ãŸã‚Šã¯ã—ãªã„ã§ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯ç„¡ç†ã«æ—¥æœ¬èªã«ã›ãšè‹±å˜èªã€ã‚«ã‚¿ã‚«ãƒŠã®ã¾ã¾ã§ã‚‚OKã§ã™ã€‚
ã ãƒ»ã§ã‚ã‚‹èª¿ã«ã—ã¦ãã ã•ã„ã€‚

Markdownã¨ã—ã¦ä½“è£ã‚’æ•´ãˆã¦ãã ã•ã„ã€‚ç‰¹ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§å¤‰æ›ã—ã¦ãã ã•ã„ï¼š
- è¦‹å‡ºã—ãƒ¬ãƒ™ãƒ«ã¯Markdownã§è¡¨ç¾ã—ã¦ãã ã•ã„
- '1 ã¯ã˜ã‚ã«'â†’'# 1 ã¯ã˜ã‚ã«' (æ•°å­—ã‚’å«ã‚ã¦å¤‰æ›)
- '2.1 é–¢é€£ç ”ç©¶'â†’'## 2.1 é–¢é€£ç ”ç©¶' (æ•°å­—ã‚’å«ã‚ã¦å¤‰æ›)
- '3.1.2 å®Ÿé¨“æ–¹æ³•'â†’'### 3.1.2 å®Ÿé¨“æ–¹æ³•' (æ•°å­—ã‚’å«ã‚ã¦å¤‰æ›)
- Markdownã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã«å…¥ã‚Œãªã„ã§ã€ãã®ã¾ã¾è¿”ã—ã¦ãã ã•ã„

ã¤ã¾ã‚Šã€è¦‹å‡ºã—ã®éšå±¤ã¯ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æ±ºå®šã—ã¾ã™ï¼š
- 1æ®µéš(section)ãªã‚‰'#'ï¼ˆä¾‹ï¼š1ã€2ã€3â†’# 1ã€# 2ã€# 3ï¼‰
- 2æ®µéš(subsection)ãªã‚‰'##'ï¼ˆä¾‹ï¼š1.1ã€2.1ã€3.1â†’## 1.1ã€## 2.1ã€## 3.1ï¼‰
- 3æ®µéšï¼ˆsubsubsectionï¼‰ãªã‚‰'###'ï¼ˆä¾‹ï¼š1.1.1ã€2.1.1ã€3.1.1â†’### 1.1.1ã€### 2.1.1ã€### 3.1.1ï¼‰

---
{previous_headers_text}
---

ä»Šå›ç¿»è¨³ã™ã‚‹ãƒšãƒ¼ã‚¸ï¼š
{text}"""
        # ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆã®è¡¨ç¤º
        retry_count = 1
        if hasattr(translate_text, 'retry'):
            retry_obj = getattr(translate_text, 'retry')
            if hasattr(retry_obj, 'statistics') and retry_obj.statistics.get('attempt_number') is not None:
                retry_count = retry_obj.statistics.get('attempt_number')
        if retry_count > 1:
            page_str = f"ãƒšãƒ¼ã‚¸ {page_info['current']}/{page_info['total']}" if page_info else "ç¾åœ¨ã®ãƒšãƒ¼ã‚¸"
            tqdm.write(f"  â†» {page_str} ã®ç¿»è¨³ã‚’å†è©¦è¡Œä¸­ (è©¦è¡Œ {retry_count}/{MAX_RETRIES})")
        
        # LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
        start_time = time.time()
        
        # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãå‘¼ã³å‡ºã—
        result = call_llm_with_retry(llm_provider, model_name, prompt)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã®æ•´å½¢å‡¦ç†ã‚’é©ç”¨
        result = clean_markdown_headers(result)
        
        elapsed_time = time.time() - start_time
        
        # ãƒšãƒ¼ã‚¸æƒ…å ±ãŒã‚ã‚Œã°ã€ãƒ­ã‚°ã«æ®‹ã™ï¼ˆtqdmã¨ç«¶åˆã—ãªã„ã‚ˆã†ã«ï¼‰
        if page_info:
            if retry_count > 1:
                tqdm.write(f"  âœ“ ãƒšãƒ¼ã‚¸ {page_info['current']}/{page_info['total']} ({char_count}æ–‡å­—) - {retry_count}å›ç›®ã®è©¦è¡Œã§ {elapsed_time:.1f}ç§’ã§ç¿»è¨³å®Œäº†")
            else:
                tqdm.write(f"  âœ“ ãƒšãƒ¼ã‚¸ {page_info['current']}/{page_info['total']} ({char_count}æ–‡å­—) - {elapsed_time:.1f}ç§’ã§ç¿»è¨³å®Œäº†")
        
        return result, extract_headers(result)
    except RETRY_EXCEPTIONS as e:
        # ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†ç™ºç”Ÿã•ã›ã¦ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã«ã‚­ãƒ£ãƒƒãƒã•ã›ã‚‹
        retry_count = 1
        if hasattr(translate_text, 'retry'):
            retry_obj = getattr(translate_text, 'retry')
            if hasattr(retry_obj, 'statistics') and retry_obj.statistics.get('attempt_number') is not None:
                retry_count = retry_obj.statistics.get('attempt_number')
        remaining = MAX_RETRIES - retry_count
        
        if remaining > 0:
            # ã¾ã ãƒªãƒˆãƒ©ã‚¤å›æ•°ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆ
            page_str = f"ãƒšãƒ¼ã‚¸ {page_info['current']}/{page_info['total']}" if page_info else "ç¾åœ¨ã®ãƒšãƒ¼ã‚¸"
            error_type = type(e).__name__
            
            # DeadlineExceededã‚¨ãƒ©ãƒ¼ã‚’ç‰¹åˆ¥ã«å‡¦ç†
            if "DeadlineExceeded" in error_type or "Deadline Exceeded" in str(e) or "504" in str(e):
                tqdm.write(f"  ! {page_str} ã®ç¿»è¨³ã§ã€ŒDeadlineExceededã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (æ®‹ã‚Š{remaining}å›)")
            # 504ã‚¨ãƒ©ãƒ¼ã‚’ç‰¹åˆ¥ã«å‡¦ç†
            elif isinstance(e, HTTPStatusError) and e.status_code == 504:
                tqdm.write(f"  ! {page_str} ã®ç¿»è¨³ã§ã€Œ504 ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã€ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (æ®‹ã‚Š{remaining}å›)")
            else:
                tqdm.write(f"  ! {page_str} ã®ç¿»è¨³ã§ã€Œ{error_type}ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (æ®‹ã‚Š{remaining}å›): {str(e)}")
            
            # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã¦ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿å´ã§ãƒªãƒˆãƒ©ã‚¤ã•ã›ã‚‹
            raise
        else:
            # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ãŸå ´åˆ
            error_type = type(e).__name__
            error_msg = f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼ (æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°{MAX_RETRIES}å›ã«é”ã—ã¾ã—ãŸ): {error_type} - {str(e)}"
            tqdm.write(f"  âœ— {error_msg}")
            return f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}", []
    except Exception as e:
        # ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡å¤–ã®ã‚¨ãƒ©ãƒ¼
        error_type = type(e).__name__
        error_msg = f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼ ({error_type}): {str(e)}"
        tqdm.write(f"  âœ— {error_msg}")
        return f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}", []

if __name__ == "__main__":
    sample_text = "Hello, world!"
    translated, headers = translate_text(sample_text, "ja", llm_provider="openai")
    print("Translated text:", translated)
    print("Extracted headers:", headers)